{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea926c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import CONFIGS\n",
    "device = CONFIGS[\"device\"]\n",
    "batch_size = CONFIGS[\"batch_size\"]\n",
    "num_components = CONFIGS[\"num_components\"]\n",
    "loss_sample_batch_size = CONFIGS[\"loss_sample_batch_size\"]\n",
    "flatness_threshold_factor = np.e\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from models.mlp import MLP\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./mnist_data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIGS[\"batch_size\"],\n",
    "    shuffle=True\n",
    ")\n",
    "sub_loader = DataLoader(train_dataset, \\\n",
    "    batch_size=loss_sample_batch_size, sampler=SubsetRandomSampler(indices))\n",
    "\n",
    "model = MLP(input_dim=28*28, hidden_dim=50, output_dim=10).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=CONFIGS[\"learning_rate\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def calculate_subset_loss(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += criterion(output, target).item() * data.size(0)\n",
    "    return total_loss / len(data_loader.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nloading data, model, and PCA results...\")\n",
    "try:\n",
    "    mean_weight = np.load('data/mean_weight.npy')\n",
    "    pca_components = np.load('data/pca_components.npy')\n",
    "    variances = np.load('data/pca_variances.npy')\n",
    "    model_state_dict = torch.load('data/final_model.pth')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"error: {e.filename} not found.\")\n",
    "    print(\"please run 'train_model.py' and 'run_pca.py' first.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3be216",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"calculating baseline loss L0 on the data subset...\")\n",
    "w0_tensor = torch.tensor(mean_weight.reshape(50, 50), dtype=torch.float32).to(device)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.fc2.weight.data = w0_tensor\n",
    "\n",
    "L0 = calculate_subset_loss(model, sub_loader, criterion, device)\n",
    "flatness_threshold = L0 * flatness_threshold_factor\n",
    "print(f\"baseline Loss L0 (on subset): {L0:.6f}\")\n",
    "print(f\"flatness Threshold (L0 * e): {flatness_threshold:.6f}\")\n",
    "\n",
    "if not os.path.exists('plots'):\n",
    "    os.makedirs('plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e314799",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "analysis_indices = [10, 20, 50, 100]\n",
    "dtheta_range = np.linspace(-10, 10, 81)\n",
    "\n",
    "for i in tqdm(analysis_indices, desc=\"loss landscape\"):\n",
    "    p_i = pca_components[i]\n",
    "    p_i_tensor = torch.tensor(p_i.reshape(50, 50), dtype=torch.float32).to(device)\n",
    "\n",
    "    losses = []\n",
    "    for dtheta in dtheta_range:\n",
    "        model.fc2.weight.data = w0_tensor + dtheta * p_i_tensor\n",
    "        loss = calculate_subset_loss(model, sub_loader, criterion, device)\n",
    "        losses.append(loss)\n",
    "    \n",
    "    plt.plot(dtheta_range, losses, label=f\"PCA index {i}\")\n",
    "\n",
    "plt.title(\"Loss landscape along PCA directions\")\n",
    "plt.xlabel(r\"$\\delta\\theta$\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.savefig('plots/loss_landscapes.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
